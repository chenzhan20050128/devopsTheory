# 具体方案进阶：OpenStack 日志序列级提前预警与剩余故障时间预测

> 目标：在现有 TextCNN 实时异常检测基线之上，构建能够 **提前 N 个日志窗口预测潜在异常并估计剩余安全时间 (Remaining Time to Failure, RTF)** 的深度学习系统，为 DevOps 团队争取自动化干预时间窗口，减少停机损失。

---

## 0. 数据与问题重新界定

### 0.1 现有资产复盘
- **原始数据**：`OpenStackData/` 内包含 `openstack_normal*.log`、`openstack_abnormal.log` 以及 `anomaly_labels.txt`。
- **基线管线**：`src/data.py` 已实现滑窗 (size=8, stride=4) 与基于实例 ID / request-id / 关键词的动态标签；`src/train.py` 输出窗口级异常标签。
- **指标现状**：TextCNN 在窗口级分类上达成 Accuracy=88.75%、F1=0.7186、Recall=0.8813，为后续任务提供可靠的“异常发生点”基准。

### 0.2 新任务定义
我们将窗口级序列数据拓展为 **提前预警** 与 **剩余时间估计** 的多任务问题。
- **输入**：时间序列 \( \mathbf{x}_{t-k+1:t} \)，每个时间步对应一个日志窗口的多模态特征（文本、数值、上下文 ID）。
- **输出 1 （分类）**：\( y^{\text{class}}_t=1 \) 表示在未来 \( \Delta t \) 时间（或 \( H \) 个窗口）内首次出现异常。
- **输出 2 （回归）**：\( y^{\text{rtf}}_t \in \mathbb{R}^+ \) ，预测距离下一次异常发生的窗口数（或分钟数）。
- **业务目标**：Recall@TopK ≥ 0.8，平均提前量 ≥ 2 个窗口，RTF MAE ≤ 1.0 个窗口。

---

## 1. 数据构建方案

### 1.1 时间切片与滑窗扩展
1. **窗口复用**：沿用 `window_size=8, stride=4` 的窗口化结果，保证与基线实验可比。
2. **序列拼接**：为训练序列模型，进一步构造长度为 `sequence_length = 12`（可调）的窗口序列，即每个样本包含连续 12 个窗口的特征，覆盖约 48 条原始日志。

### 1.2 提前预警标签生成
设某实例/请求在窗口 \( t^* \) 首次标记为异常：
- 对于之前窗口 \( t^* - h \) (\( h=1..H \))，若 \( h \le H_{alert} \)（如 3 个窗口 ≈12 条日志），则赋予 `y_class=1`，表示该窗口处于“异常前兆阶段”。
- 同时记录 \( y^{\text{rtf}} = h \) 作为剩余窗口数。超过预警范围 (\( h > H_{alert} \)) 的窗口保持 `y_class=0`。
- 若一个窗口后续未在任意 \( H_{alert} \) 内出现异常，则 `y_class=0`，`y^{\text{rtf}}` 设为最大阈值或使用掩码忽略。

### 1.3 负样本与采样策略
- **负样本池**：选择远离任何异常的长序列窗口段（例如最近 10 个窗口均为正常）的序列作为稳定背景。
- **比例控制**：正:负 ≈ 1:3，确保模型关注正样本同时维持数据平衡。
- **时间切分**：按照时间顺序划分 train/val/test，防止未来信息泄漏到过去。

### 1.4 特征扩展
1. **文本特征**：沿用标准化文本，使用与基线一致的词表或预训练 BERT tokenizer（可选微调）。
2. **数值统计**：保留 5 维统计量并在序列层面拼接。
3. **时间编码**：为每个窗口添加：小时 of day、weekday、分钟偏移，使用 sin/cos 周期编码。
4. **标识嵌入**：
   - `instance_id`、`request_id`（截断/哈希）映射至嵌入向量。
   - `source_file`（normal1 / normal2 / abnormal）追加 one-hot。
5. **历史异常频次**：维护滑动窗口内“异常计数”或“错误关键词计数”作为辅助信号。

### 1.5 数据输出格式
- 采用 `torch.utils.data.Dataset` 输出 `(sequence_tensor, numeric_tensor, categorical_ids, y_class, y_rtf, mask)`。
- 序列张量形状：`[sequence_length, token_length]`；数值特征形状：`[sequence_length, numeric_dim]`。
- 为支持批量训练，通过自定义 `collate_fn` 进行 padding（若使用可变序列）。

---

## 2. 模型设计

### 2.1 架构选型与理由
我们选取 **Temporal Fusion Transformer (TFT)** 改造版作为主干：
- **多头注意力** 捕捉长程依赖。
- **门控残差网络 (GRN)** 处理静态/时间-varying 特征。
- **多任务输出层** 同时服务分类与回归目标。
- 与 TCN / Informer 互为备选，可在实验阶段加入 ablation。

### 2.2 模块拆分
1. **静态编码器**：处理实例 ID / 请求 ID 嵌入，输出静态上下文向量。
2. **时间特征编码器**：对每个时间步的文本、数值、时间特征进行投影并相加融合。
3. **Seq Encoder**：基于多头注意力 + 前馈网络构建；可选引入相对位置编码。
4. **多任务头**：
   - `Head_class`：线性层 + Sigmoid，输出提前预警概率。
   - `Head_rtf`：线性层输出剩余窗口预测，使用 Softplus 保证非负。

### 2.3 损失函数
- `L_class = BCEWithLogitsLoss`，对正样本设置较高权重以关注召回。
- `L_rtf = SmoothL1Loss`，并对缺失值使用 `mask` 忽略。
- 总损失：`L_total = L_class + λ * L_rtf`，建议 λ=0.5 起步，可通过验证集调优。

### 2.4 训练细节
- **优化器**：AdamW，`lr = 1e-3`，配合 OneCycleLR 或 CosineAnnealingLR 提升收敛。
- **批大小**：`batch_size = 32`（根据 GPU 可调）。
- **正样本过采样**：若召回不足，可引入 WeightedRandomSampler。
- **早停策略**：监控验证集 Recall@TopK 与 RTF MAE；若连续 5 epoch 无提升则停止。

### 2.5 推理策略
- 实时推理时维护长度为 `sequence_length` 的滑动缓冲区，在线更新特征并输出：
  - `alert_score`：提前预警概率。
  - `eta`：预测剩余窗口数。
- 根据阈值将输出划分为“观察”“警戒”“立即干预”三档，为 DevOps Pipeline 触发不同自动化动作。

---

## 3. 评估方案

| 指标 | 含义 | 目标值 | 备注 |
| --- | --- | --- | --- |
| Recall@Top20% | 取预警分最高的 20% 窗口，真实异常覆盖率 | ≥ 0.80 | 强调提前发现能力 |
| Precision@Top20% | 预警有效性 | ≥ 0.40 | 控制误报 |
| AUPRC | 整体阈值无关表现 | 越高越好 | 类别不平衡更适用 |
| Avg Lead Time | 对所有成功预警的样本，平均提前窗口数 | ≥ 2.0 | 体现缓冲时间 |
| RTF MAE | 剩余窗口预测平均绝对误差 | ≤ 1.0 | 衡量时间估计准确度 |
| Deployment Latency | 线上推理延迟 | ≤ 200ms | 满足实时性 |

评估流程：
1. 按时间切分数据，采用滚动回测（walk-forward validation）。
2. 保存每次验证的 ROC / PR 曲线、Lead Time 分布图、误报案例分析。
3. 与基线方法（关键词阈值、XGBoost）比较提升幅度。

---

## 4. DevOps 集成路径

1. **数据通道**：
   - 使用 Fluentd/Logstash 收集日志 → Kafka Topic → Spark/Flink 预处理 → 写入 Feature Store。
   - 实验阶段使用离线批处理脚本复现，MVP 可先跑离线预测。
2. **在线推理服务**：
   - 基于 FastAPI/FastStream 部署推理微服务，加载训练好的 TFT 模型。
   - 暴露 `/predict` 接口，输入最新窗口特征，输出 `alert_score` 与 `eta`。
3. **告警策略**：
   - 低置信度 (`score < 0.4`)：记录观察日志，不触发动作。
   - 中置信度 (`0.4 ≤ score < 0.7`)：推送至运维看板，标记为“预警”。
   - 高置信度 (`score ≥ 0.7`)：自动创建工单/触发 scale-out、迁实例等脚本。
4. **反馈闭环**：
   - 工单状态 & 运维确认作为“真/伪预警”反馈，写入标签仓。
   - 每周/每月增量训练，使用 MLflow/DVC 管理模型版本。

---

## 5. 实施计划与资源估算

| 阶段 | 周期 | 关键交付 | 说明 |
| --- | --- | --- | --- |
| P0 | 1 | 数据切片与标签生成脚本；验证数据质量报告 | 完成 `src2/data.py` 原型，确认正负样本分布 |
| P1 | 2 | TFT 模型初版 + 训练脚本 | 实现 `src2/model.py`, `src2/train.py`；离线单机训练 |
| P2 | 1 | 指标评估与对比实验 | 输出回测报告，确定最佳 λ、阈值 |
| P3 | 2 | 在线推理原型 + REST 接口 | 实现推理入口（可选 `src2/service.py`）|
| P4 | 2 | 测试与运维接入 | 集成 Kafka/FastAPI，完成告警联调 |

- **算力**：单卡 RTX 4090 / A100 皆可，显存需求 ~16GB。离线初期可用 3090。
- **存储**：特征与标签约 2~3 GB，模型权重 < 200MB。

---

## 6. 风险与应对

| 风险 | 影响 | 应对策略 |
| --- | --- | --- |
| 标签不平衡导致 Recall 低 | 预警遗漏 | 使用 Focal Loss / 调整 λ，或引入代价敏感采样 |
| 序列过长导致训练慢 | 开发进度拖延 | 采用分层序列、因果卷积或截断策略；缓存特征 |
| RTF 回归噪声大 | 时间估计不稳定 | 使用分段线性回归、Quantile Loss 捕捉区间 |
| 线上特征漂移 | 性能衰减 | 监控实时指标，触发模型回滚与重训 |

---

## 7. 与代码实现的映射关系

为确保方案可落地，我们将在 `openstack_textcnn/src2/` 目录中实现以下模块：
- `data.py`：负责序列构建、标签生成、Dataset & DataLoader；支持参数化的 `sequence_length`、`horizon`。
- `features.py`（可选）：封装时间/ID 特征编码逻辑，便于复用。
- `model.py`：实现 TFT/TCN 混合模型，提供 `forward(inputs)` 返回分类 logits 与 RTF 预测。
- `train.py`：训练入口，集成配置解析、训练循环、指标计算与模型持久化。
- `metrics.py`：封装 Recall@TopK、平均提前量、RTF MAE 等评估函数。
- `inference.py`（拓展）：示例化在线推理流程。

上述代码与文档形成闭环，便于后续直接按照此路线推进实验与部署。